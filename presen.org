#+title: Classical Planning in Deep Latent Space: From Unlabelled Images to PDDL (and back) 
#+include: "head.org"
#+LINK: img file:img/%s
#+LINK: png file:img/%s.png
#+LINK: jpg file:img/%s.jpg
#+LINK: svg file:img/%s.svg
#+LINK: spng file:img/static/%s.png
#+LINK: sjpg file:img/static/%s.jpg
#+LINK: ssvg file:img/static/%s.svg
#+LINK: sgif file:img/static/%s.gif

#+begin_outline-text-1
#+begin_center

#+begin_larger
_Masataro Asai_, Alex Fukunaga, The University of Tokyo
#+end_larger

20+ min
#+end_center

#+begin_note
#+begin_alignright
Made by guicho2.71828 (Masataro Asai)
#+end_alignright
#+end_note
#+end_outline-text-1

* 

#+begin_xlarge
#+begin_center
Hello, Machine Learning people!
#+end_center
#+end_xlarge

#+begin_resume
First of all, hello machine learning people.
Im not a machine learning person.
Im usually studying a type of symbolic AI and I visited here expecting an interesting conversation with
machine learning professionals.
#+end_resume

* 

#+begin_xlarge
#+begin_center
Hello, Logic Programming, Data Mining, AGI, Theoretical CS people, too!
#+end_center
#+end_xlarge

#+begin_resume
And also, hello other symbolic AI people.
Although I am not doing exactly the same thing, we have common roots.

Let me give you one question before presenting my paper...
#+end_resume

* How many people have learned AI with these books?

#+begin_container-fluid
#+begin_row-fluid
#+begin_span4
[[sjpg:aima1]]
#+end_span4
#+begin_span4
[[sjpg:aima2]]
#+end_span4
#+begin_span4
[[sjpg:aima3]]
#+end_span4
#+end_row-fluid
#+end_container-fluid

#+begin_alignright
+ Nice.
#+end_alignright

* 

#+begin_xlarge
#+begin_center
I am from */Planning/* community
#+end_center
#+end_xlarge

#+begin_center
[[sgif:icapslogo]]

International Conference on Automated Planning and Scheduling

(AAAI sister conference, 33% avg. accept ratio, since 1990, ECP+AIPS→ICAPS)
#+end_center

* Planning people are working on */Automated Planners/*

+ Compute the *high-level plan* for an agent: /plan = (action_1, action_2, ... action_n)/
  + Search-based planning projects many steps further into the future than RL
  + ↔ reflex (0-step), limited deliberation (1,2-steps)
+ High-dimensional, *implicit* state space search
  + Entire space does not fit in memory, only *transition rules* are given
+ STRIPS-like *PDDL modelling language*, based on
  + 1st-order logic, close-world assumption
+ *Soundness, completeness, optimality* matters
  + Expensive Applications: Satellite operations (Deep Space 1), Mars Exploration Rover (MER), underwater vehicles

* High-level Planning: Sliding tile puzzle (a.k.a 8-puzzle)

#+begin_container-fluid
#+begin_row-fluid
#+begin_span8
+ Slide a tile to an empty place (each step)
+ → make the tile placement identical to the goal
+ → (abstracts the low level control e.g. arm motion)
+ *Search states* represented by conjunctions of 1st-order logic (objects, predicates, propositions)
  #+begin_src lisp
  (empty x0 y0)     ; or, empty(x0, y0)
  (is panel6 x1 y0) ; or, is(panel6, x1, y0)
  (up    y0 y1)... (down  y1 y0)...
  (right x0 x1)... (left  x0 x1)...
  #+end_src
#+end_span8
#+begin_span2
initial state
[[png:8puzzle-standard]]
#+end_span2
#+begin_span2
goal state
[[png:8puzzle-standard-goal]]
#+end_span2
#+end_row-fluid
#+begin_row-fluid
#+begin_span12
+ To symbolic systems *names do not matter* (just matters to human) as long as there is consistency
  #+begin_src lisp
  (car   banana0 kiwi0)           ; numbers (0,1) don't matter either
  (shark bogo6 banana1 kiwi0)     ; just to make sense for us
  (apple  kiwi0 kiwi1)... (pinapple kiwi1 kiwi0)...
  (pen    banana0 banana1)... (applepen banana0 banana1)...
  #+end_src
#+end_span12
#+end_row-fluid
#+end_container-fluid

** High-level Planning Task: State Transitions

#+begin_container-fluid
#+begin_row-fluid
#+begin_span9
How to represent "sliding up tile 7" ? → *actions*

#+begin_quote
Transition Rules of "sliding up":

+ You can slide up a tile only to an empty location.

+ When you slide it, the orignal location becomes empty.

+ New location is no longer empty, is occupied by the tile.
#+end_quote
#+end_span9
#+begin_span3
initial state
[[png:8puzzle-standard-tile7]]
#+end_span3
# #+begin_span2
# goal state
# [[png:8puzzle-standard-goal]]
# #+end_span2
#+end_row-fluid
#+begin_row-fluid
#+begin_span12
+ When /Empty(x, y_{old}) ∧ is(panel, x, y_{new}) ∧ up(y_{new}, y_{old})/ ;
  
  then /¬ Empty(x,y_{old}) ∧ Empty(x,y_{new}) ∧ ¬ is(panel, x, y_{new}) ∧ is(panel, x, y_{old})/

+ 
  #+begin_src lisp
  ;; Translates to a PDDL model below:
  (:action slide-up ...
   :precondition (and (empty ?x ?y-old)
                      (is ?panel ?x ?y-new) ...)
   :effects (and (not (empty ?x ?y-old))     (empty ?x ?y-new)
                 (not (is ?panel ?x ?y-new)) (is ?panel ?x ?y-old)))
  #+end_src

# #+begin_src lisp
# (:action move-up
#  :parameters (?x ?y-old ?y-new ?panel)
#  :precondition (and (empty ?x ?y-old)
#                     (up ?y-old ?y-new)
#                     (is ?panel ?x ?y-new))
#  :effects (and (not (empty ?x ?y-old))
#                (empty ?x ?y-new)
#                (not (is ?panel ?x ?y-new))
#                (is ?panel ?x ?y-old)))
# #+end_src
#+end_span12
#+end_row-fluid
#+end_container-fluid

+ 
  #+begin_larger
  #+begin_alignright
  But *where does this representation come from?*
  #+end_alignright
  #+end_larger

** PDDL representations come from */human encoding/*.

#+begin_quote
*Knowledge-Acquisition Bottleneck (Cullen, 1988)*:

The *cost of human involved* for converting real-world problems into inputs for
domain-independent *symbolic* systems
#+end_quote

+ *Symbols: Labels for identifiable entities* (it's not just about objects!)

  | Types of symbols  |                                            |
  |-------------------+--------------------------------------------|
  | Object symbols    | panel7, x_0, y_0 ...                       |
  | Predicate symbols | (*empty* ?x ?y) (*up* ?y_0 ?y_1)           |
  | Propositions      | *p_28* = (empty x_0 y_0) --- application |
  | Action symbols    | (*slide-up* panel_7 x_0 y_1)               |

+ *Action Model: Description of Actions using Symbols*

  　
  
  #+begin_center
  When /Empty(x, y_{old}) ∧ .../ ; Then /¬ Empty(x,y_{old}) ∧ / ...
  #+end_center

#+begin_note
The knowledge acquisition bottleneck: time for reassessment? : Cullen, J and Bryman, A Expert Syst. Vol 5 No 3 (August 1988) pp 216-225
#+end_note

** Can we solve an 8-puzzle optimally, w/o human encoding?

#+begin_center
+ 3x3 Image-based Sliding Tile Puzzle: maximum 31 steps *optimal* plan

+ 4x4、5x5 : infeasible under blind search (memory exhaust)

+ Symbolic systems can compute *optimal* solutions w/ A* + admissible heuristics
#+end_center

#+begin_container-fluid
#+begin_row-fluid
#+begin_span8
[[sjpg:puzzle]]
#+end_span8
#+begin_span4
+ 
   #+begin_center
   *BUT*

   *WE*

   *DO*

   *NOT*

   *HAVE*

   */SYMBOLS/*

   *NOR*

   */AN ACTION MODEL/!*
#+end_center
#+end_span4
#+end_row-fluid
#+end_container-fluid

* Backgrounds

#+begin_xlarge
Survey of Exisiting Action Model Acquisition Techniques
#+end_xlarge

　

#+begin_alignright
i.e. Systems that find action models
#+end_alignright

** Limitations of Existing Systems

#+begin_xlarge
#+begin_center
So far, ALL existing AMA systems require */symbolic / near-symbolic, accurate state inputs/* and/or */discrete action labels/*.
#+end_center
#+end_xlarge

#+begin_alignright
i.e. They need symbols to find an action model
#+end_alignright

** ARMS (Action-Relation Modelling System) (Yang AIJ07)

Taking the *symbolic* inputs

[[spng:arms]]

** LOCM (ICAPS09)

Taking the *symbolic* inputs

[[spng:locm]]

** Framer (ICAPS17)

*Near-Symbols* : Parses natural language sentences with a *clear grammatical structure*.


#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
[[spng:framer]]
#+end_span6
#+begin_span6
+ Alleviates the burden of domain experts, but *still requires human*
+ Not handling "Natural Language":
  
  #+begin_quote
  Pick up that parcel over there ... yeah, it has a label on it, it says Parcel1, you can see
  it from here, the Location B. Then put it in the car, I mean the truck, the red one.
  #+end_quote
#+end_span6
#+end_row-fluid
#+end_container-fluid

** Konidaris, Kaelbring (AAAI14, IJCAI15)

"Constructing Symbolic Representations for High-Level Planning" (AAAI14)

+ What it does :: Converting a *Semi-MDP Model* to a *PDDL Model* by set-theoretic representation
                  
                  i.e. *Model-to-Model* conversion, not *generating a model from the scratch*
+ Semi-MDP contains Action Labels :: =move= and =interact= (Playroom)
+ Sensor inputs are structured (Labels for "State Variable" are known) :: 

     x/y-distance, light level, whether a monkey cries
     
     → Each sensor has a distinct meaning (no overwrap)

# + Low-dimensional, accurate input :: 33 vars (Playroom), 9 vars (Treasure), no noise
#      
#      Although IJCAI15 shows "visual depiction", it is not used by the system

** Learning from Observation (Argall AIJ09, Mourao UAI12)              :skip:

Noisy, incomplete, but symbolic states/actions

[[spng:mourao]]

[[spng:mourao2]]

** Learning from Video for Board Game (Bardu ICRA10; Kaiser AAAI12; Kirk 16) :skip:

+ Handles Images, but with strong assumptions (almost symbol) ::
     e.g. Understands *Tic-Tac-Toe* with *3x3 Ellipse Detector* (Bardu 10)
     
     Almost immediately provides propositions

     Domain-dependent ("3x3 grid" is hard-coded)

* Problem Description

#+begin_center
We do not have */SYMBOLS/* nor */ACTION MODELS/*

*/So we cannot apply existing AMA methods!/*
#+end_center

[[sjpg:puzzle]]

** Task: Solving */Imaged-Based/* 8-puzzle w/o Prior Explicit Knowledge

*No Prior Knowledge* : labels/symbols such as "9 tiles", "moving"

[[sjpg:puzzle]]

** Task: Solving */Imaged-Based/* 8-puzzle w/o Prior Explicit Knowledge

*/No Prior Knowledge/* : labels/symbols such as "9 tiles", "moving"

[[sjpg:puzzle]]

** Task: Solving */ANY/* Imaged-Based tasks w/o Prior Explicit Knowledge

#+begin_larger
*/No Prior Knowledge/* : */Domain-independent Image-based planner/*
#+end_larger

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
Tower of Hanoi

[[sjpg:hanoi]]
#+end_span6
#+begin_span4
Lights-Out

[[sjpg:lightsout]]
#+end_span4
#+end_row-fluid
#+end_container-fluid

** Input1: Training Inputs -- Image Pairs

Image pairs showing the before/after states of valid actions (randomly sampled)

[[png:overview/1]]

** Input1: Training Inputs -- Image Pairs

[[png:overview/2]]

** Input2: Planning Inputs -- Initial Image & Goal Image

Visual depiction of the initial state and a single goal state

[[png:overview/input2]]

** Task: Solving */ANY/* Imaged-Based tasks w/o Prior Explicit Knowledge

#+HTML: <embed src="img/overview/3.svg" type="image/svg+xml"  />

#+begin_larger
　

　
#+end_larger

** Task: Solving */ANY/* Imaged-Based tasks w/o Prior Explicit Knowledge

#+HTML: <embed src="img/overview/3-hanoi.svg" type="image/svg+xml"  />

* *Our Core Contribution : State AutoEncoder (SAE)*

SAE is a *neural network* which provides two functions:

+ $b = Encode(r)$ : *Function that maps a raw datum $r\;$ to a bit vector $b\;$ (propositions)*

+ $\tilde{r} = Decode(b)$ : *Function that maps a bit vector $b\;$ to a raw datum $\tilde{r}$*

+ *A bidirectional mapping between subsymbolic & symbolic representation*

** Neural Network 101                                              :noexport:

[[png:deeplearning/1]]

** Neural Network 101                                              :noexport:

[[png:deeplearning/2]]

** Neural Network 101                                              :noexport:

[[png:deeplearning/3]]

** Stochastic Gradient Descent + GPU                               :noexport:

[[spng:gradient-descent]]

Plus misc techniques e.g. *Batchnorm*, *Dropout*

#+begin_larger
*Pretty much everything is on the standard online tutorial / lecture cource / MOOP*

*Good libraries --- Tensorflow, Keras* --- you can learn in 1-2 months
#+end_larger

** Standard Classification / Mapping Tasks                         :noexport:

Target Function $y^*=f^*(x)$
  
| Task                 | Input x  | Output y                           |
|----------------------+----------+------------------------------------|
| Image classification | Image    | Label (1=car, 2=cat, 3=monkey ...) |
| Translation          | Sentence | Sentence                           |
| Go eval. function    | State    | Number                             |

#+begin_larger
 + *This is not suitable for our task; /there is no label, answers/*
#+end_larger

** AutoEncoder : Unsupervised Learning

Auto = "self" --- Autoencoding = "encoding itself"

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
+ Target Function: Identity $x=f^*(x)$
+ Compression: $X \rightarrow Z \rightarrow X$
+ Map the input $x\;$ to a *latent vector* $z$, then back to $x$
+ Extract the de/compressor: $Encode: x \mapsto z, Decode: z \mapsto x$
#+end_span6
#+begin_span6
[[png:static/autoenc]]
#+end_span6
#+end_row-fluid
#+end_container-fluid

#+begin_alignright
#+begin_larger
+ → However, */✘ Latent vector is real-valued/*

  */INCOMPATIBLE to classical planning/*
#+end_larger
#+end_alignright

** Variational AutoEncoder (VAE)                                   :noexport:

An AutoEncoder that *enforce a certain distribution* on $Z \subset \mathbb{R}^n$ over the dataset $X$

#+begin_quote
You have $X=$ { 10k images of apples }. If you train a *Gaussian VAE* on $X$, then $Z = Encode(X) \approx N(\mu,\sigma)$ for some $\mu,\sigma \in \mathbb{R}^n$.
#+end_quote

VAE needs a *reparametrization trick* because random distributions are non-differentiable.

#+begin_quote
Reparametrization for $N(\mu,\sigma)$: $\mu + \sigma N(0,1)$

#+begin_center
\mu and \sigma are differentiable vectors, $N(0,1)$ is not.
#+end_center
#+end_quote

** Gumbel-Softmax VAE (Jang, Gu, ICLR2017)

A reparametrization trick for *categorical distribution*: 1-hot vector e.g.  $\langle 0,0,0,1,0,0 \rangle$ .

Below: Represent an MNIST image with 30 variables of 8 categories.

#+begin_center
 #+begin_html
 <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="649px" height="206px" version="1.1" content="&lt;mxfile userAgent=&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36&quot; version=&quot;6.0.1.2&quot; editor=&quot;www.draw.io&quot; type=&quot;google&quot;&gt;&lt;diagram name=&quot;Page-1&quot;&gt;3ZhLc5swEMc/Dcd0kAQCX+O67SGd6TTTaXqU0fJoZcsjy69++oogDBjs0MZ2TONDpL9ey29Xi5BDxrPtR8UW6WfJQTjY5VuHvHcwxshF5l+u7AqF+rgQEpXxQkKV8Jj9Biu6Vl1lHJaNjlpKobNFU4zkfA6RbmhMKblpdoulaK66YAm0hMeIibb6PeM6LdTQdyv9E2RJWq6MXNsyY2VnKyxTxuWmJpGJQ8ZKSl2UZtsxiBxeyaUY9+FI694wBXPdZ0AQh1EYx4xP46kXRHBnZ1gzsbIPaw3Vu/LpN2mm4XHBory+MR52yH2qZ8LUkCnGmRBjKaR67k0AcR8Coy+1kr+g1jKiAWHUtCi5mnPgdrw1AJSG7dGnQntWJshAzkCrneliB5CAFENsfCHPL+qbylt7n6Q1T+HAisxGSLKfu4JoCpZjT6a4xRT71MFUmFXvebY2xSQvfoWHb6VsFqm1tHygUjmbroyR9y944ww08QFN7LktmmEHzPASLEmLpY/wcFiiW2LptVAAN3nOVqXSqUzknIlJpdb2qtuEA9tMP9XKP/Iu7/y8NjeGPtkRz5Wq7SdovbMJnq20NFK17oOUiwb63LzT4M3TyJWK4HT0aKYS0Kd2a9uBCgTT2bq5/mvc4eEIU4xG4PsesCDqCO1z+ufKpBHugZq8FeorRf6VmfdBfiQ9XR45HXbi9kf4zRJ3i2Uw7AOFd0ssw//9JXgseupponu3Ht8MwYEDL+KZ0cDehyeBBqd3BB31B2pn+SIzY0D/KYqYsKMO3LK36N88hc7+1cgZhHHU9dVIoxCm8SW+GukINQm67bSEaEde2otnDX901nAfRGaiPTYSutYJ5uiRdthRfldeot1IlPfI8i9Abcb8AeLYz3+diJ//Xgm1hIg6IHpdEL1LQCxvEwcK0Q4I3IP8+8ZQX/9SuwGoJGxud+STFtSQtpli3/trpqZa3VwX54rq/p9M/gA=&lt;/diagram&gt;&lt;/mxfile&gt;"><defs/><g transform="translate(0.5,0.5)"><rect x="288" y="0.75" width="75" height="202.5" rx="11.25" ry="11.25" fill="#e1d5e7" stroke="#9673a6" pointer-events="none"/><path d="M 243 72 L 273 102 L 243 132 L 213 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(231.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">256<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 168 72 L 198 102 L 168 132 L 138 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(156.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">512<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 198 102 L 208.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 212.16 102 L 206.91 104.63 L 208.22 102 L 206.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 120.75 102 L 135.75 102 L 123 102 L 133.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 137.16 102 L 131.91 104.63 L 133.22 102 L 131.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 273 102 L 288 102 L 273 102 L 283.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 287.16 102 L 281.91 104.63 L 283.22 102 L 281.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 482.25 72 L 512.25 102 L 482.25 132 L 452.25 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(470.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">512<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 407.25 72 L 437.25 102 L 407.25 132 L 377.25 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(395.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">256<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 437.25 102 L 447.47 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 451.41 102 L 446.16 104.63 L 447.47 102 L 446.16 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 360 102 L 375 102 L 362.25 102 L 372.47 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 376.41 102 L 371.16 104.63 L 372.47 102 L 371.16 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><rect x="526.5" y="42" width="120" height="120" rx="18" ry="18" fill="#dae8fc" stroke="#6c8ebf" pointer-events="none"/><path d="M 512.25 102 L 521.72 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 525.66 102 L 520.41 104.63 L 521.72 102 L 520.41 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><rect x="0.75" y="42" width="120" height="120" rx="18" ry="18" fill="#dae8fc" stroke="#6c8ebf" pointer-events="none"/>
 <image xlink:href="img/static/x0.gif" x="8.25" y="49.5" width="105" height="105" fill="#f5f5f5" stroke="#666666" pointer-events="none"/>
 <image xlink:href="img/static/x1.gif" x="534" y="49.5" width="105" height="105" fill="#f5f5f5" stroke="#666666" pointer-events="none"/>
 <image xlink:href="img/static/y.gif" x="293.25" y="6.75" width="64.5" height="190.5" fill="#f5f5f5" stroke="#666666" pointer-events="none"/></g></svg>
 #+end_html
#+end_center

#+begin_larger
#+begin_center
Key idea: *These categorical variables are /directly/ usable*

*as a source of PDDL/SAS*

In particular, *2 categories → propositional variables (true/false)*
#+end_center
#+end_larger

** State Autoencoder (*/before training/*)

 [[png:sae/state-ae-before]]

** State Autoencoder (_/after training/_)

 [[png:sae/state-ae]]

** Gumbel-Softmax: Differential Approximation of Gumbel-Max        :noexport:

#+begin_larger
It uses *annealing* to approximate discrete vectors
#+end_larger

#+begin_smaller
Gumbel-Max: Method for drawing one-hot vector sample ($z$) from category probability ($x$)

+ E.g.: $x=[0.1, 0.1, 0.8] \rightarrow z = [1,0,0] \text{or} [0,1,0] \text{or} [0,0,1]$

+ $z = \text{ GumbelMax}(x) = [ i == \arg \max_j (\text{ Gumbel}(0,1)+\log x_j) \; ? \; 1 : 0 ]$

+ argmax is non-differentiable → softmax approximation (differentiable)

+ $z = \text{ GumbelSoftmax}_\tau (x) = \text{ Softmax}( [\text{ Gumbel}(0,1)+\log x_j]/\tau )$

+ Temparature $\tau \rightarrow 0$ , $z\rightarrow \text{one-hot vector}$

  # \[
  # \text{ GumbelSoftmax}_\tau (x) \rightarrow \text{ GumbelMax}(x) \quad (\tau\rightarrow 0)
  # \]
#+end_smaller

#+begin_container-fluid
#+begin_row-fluid
#+begin_span2

#+end_span2
#+begin_span8
#+begin_center
[[png:sae/gumbel]]
#+end_center
#+end_span8
#+begin_span2

#+end_span2
#+end_row-fluid
#+end_container-fluid

#+begin_note
Maddison et. al., 2014
#+end_note

* -                                                                :noexport:

#+begin_xlarge

#+begin_center
Classical Planning

in */Deep Latent Space/*:

From */Unlabelled Images/*

to PDDL (and back)
#+end_center
#+begin_alignright

#+end_alignright
#+end_xlarge

* Deep Neural Networks                                             :noexport:

[[png:deeplearning/1]]

** Human-competitive results in cognitive tasks

[[png:deeplearning/dl-image-task]]
* Combining Symbolic AIs and Subsymbolic AIs                       :noexport:

[[png:lecun]]

* Sure it works, how?                                              :noexport:

DLNN + Classical Planner

+ 1. Extracting knowledge from unlabelled images

  + *For what, and how?*

+ 2. Neural output is subsymbolic real-valued activations

  + Symbolic, discrete values, propositions? *Symbol Grounding*

+ 3. Machine-generated symbols are *not human-comprehensive*

  + *How to interpret these /foreign/ symbols?*

* Using SAE, we propose */LatPlan, an architechture/*

#+begin_larger
and _/LatPlanα/_, an implementation
#+end_larger

 [[png:overview/planning1]]

** Step 1: State Autoencoder (*/Core Contribution/*)

A neural network *bridging the Symbolic/Subsymbolic boundary*

 [[png:overview/planning2]]

*** Step 1: State Autoencoder (*/Core Contribution/*)              :noexport:

[[png:train-state-ae]]

Trained SAE provides two functions:

+ $b = Encode(r)$ : *Function that maps a raw datum $r\;$ to a bit vector $b\;$ (propositions)*

+ $\tilde{r} = Decode(b)$ : *Function that maps a bit vector $b\;$ to a raw datum $\tilde{r}$*
** Step 2: Action Model Acquisition (_/NOT our contribution/_)

Bitvectors → PDDL domain description

 [[png:overview/planning3]]

*** Our PDDL generation in LatPlan α (_/NOT our contribution/_)

#+begin_larger
*/Placeholder for existing/future Action Model Acquisition methods/*
#+end_larger

Individual actions are mapped to PDDL actions (trivial Actiom Model Acquisition)

#+begin_src lisp
 0011 → 0101

　　　↓

(:action ...
 :precondition (and (b0-false) (b1-false) (b2-true) (b3-true)) ; before-state
 :effect       (and (not (b1-false)) (b1-true)    ; state diff
                    (not (b2-true))  (b2-false)))
#+end_src

Conversion from a bit to a proposition:

#+begin_center
 $i$-th bit is 1 → Proposition ($b_i$ -true)

 $i$-th bit is 0 → Proposition ($b_i$ -false)
#+end_center

#+begin_note
Disclaimer: We have new AMA method based on NN (we do not disclose it yet)
#+end_note

*** Example PDDL

# Examples in $N=25$ (in the paper we bypassed PDDL-SAS translater)

#+begin_src lisp
(define (domain latent)
 (:requirements :strips)
 (:predicates (b0-true) (b0-false) (b1-true) ... (b24-false))

 (:action a10000010010110111100011111000010001011111110011111
  :parameters () :precondition
  (and (b0-true) (b1-false) (b2-false) ... (b24-true))
  :effect (and (not (b5-false))  (b5-true)
               (not (b6-true))   (b6-false)
               (not (b13-false)) (b13-true)
               (not (b20-false)) (b20-true)))

 (:action a10000010010110111100011110000001001011011110001110
  ...
#+end_src

*** Step 2: Action Model Acquisition (_/NOT our contribution/_)

Bitvectors → PDDL domain description

 [[png:overview/planning3]]



** Step 3: Solve the PDDL instance w/ off-the-shelf planner

  [[png:overview/planning4]]

** Step 4: Executing the symbolic plan

  [[png:overview/planning5]]

#+begin_alignright
#+begin_larger
We get an incomprehensive state sequence
#+end_larger
#+end_alignright

** Step 5: Mapping the plan to images (human-comprehensive)

  [[png:overview/planning6]]
* Results (MNIST 8-puzzle)

8-puzzle using digits from MNIST database

[[png:results/mnist-plan]]

#+begin_larger
An instance whose the optimal solution length is known
#+begin_xlarge
#+begin_alignright
 → *31 step optimal plan*
#+end_alignright
#+end_xlarge
#+end_larger

** Results with photographic, unseparated tiles (Mandrill 8-puzzle)

MNIST 8-puzzle has cleanly separated objects -> This domain does not.

[[png:results/mandrill-intro]]

** Results with photographic, unseparated tiles (Mandrill 8-puzzle)

[[png:results/mandrill-plan]]

#+begin_xlarge
#+begin_alignright
 → *Optimal Solution*
#+end_alignright
#+end_xlarge

** Tower of Hanoi (3 disks, 4 disks)

Completely different puzzle problem can be solved with no change

[[png:results/hanoi3]]

[[png:results/hanoi4]]

#+begin_alignright
#+begin_xlarge
 → *Optimal Solution* (7 steps,15 steps)
#+end_xlarge
#+end_alignright

** Lights Out

Completely different puzzle problem can be solved with no change

[[png:results/lights-out]]

#+begin_alignright
#+begin_xlarge
 → *Optimal Solution*
#+end_xlarge
#+end_alignright

** Twisted Lights Out

Does not assume grid-like structures

[[png:results/lights-out-skewed]]

#+begin_alignright
#+begin_xlarge
 → *Optimal Solution*
#+end_xlarge
#+end_alignright

** Handling the Noisy Input

# Denoising AE を使っているため入力ノイズに左右されずにプランを求められる

[[png:results/noise]]

#+begin_xlarge
#+begin_alignright
 → *Optimal Solutions*
#+end_alignright
#+end_xlarge
* Why bother the off-the-shelf planner? Shouldn't the blind search do?

*Domain-independent heuristics works, /SURPRISINGLY!/*

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
+ This is *NOT* a trivial finding!

  Heuristics are...

  + taylored for *man-made* domains
  
  + assuming a *certain structure*

  PDB may even sometimes lose to Blind on IPC instances (Edelkamp 12)

+ *Would allow to solve the more difficult problems (future work)*
#+end_span6
#+begin_span6
#+begin_smaller
|------------------------+----------+----------+---------|
| /                      |        < |        > | <>      |
|                        |          |      <r> |         |
| Expanded nodes         | Dijkstra |   A*+PDB | Speedup |
|------------------------+----------+----------+---------|
| MNIST 8-puzzle         |   193924 | *109096* | x2      |
| MNIST 8-puzzle         |   201156 | *111642* | x2      |
| MNIST 8-puzzle         |   186767 |  *84561* | x2      |
| MNIST 8-puzzle         |   183336 |  *82518* | x2      |
| MNIST 8-puzzle         |   169907 |  *52084* | x3      |
| MNIST 8-puzzle         |   130863 |  *26967* | x5      |
|------------------------+----------+----------+---------|
| Hanoi (4 peg)          |       55 |     *17* | x3      |
|------------------------+----------+----------+---------|
| LightsOut (4x4)        |      952 |     *27* | x30     |
|------------------------+----------+----------+---------|
| Spiral LightsOut (3x3) |      522 |    *214* | x2.5    |
|------------------------+----------+----------+---------|
| Mandrill 8-puzzle      |   335378 |  *88851* | x4      |
|------------------------+----------+----------+---------|
#+end_smaller
#+end_span6
#+end_row-fluid
#+end_container-fluid

#+begin_larger
#+begin_alignright
→ */Leverage the effort from ICAPS community!/*
#+end_alignright
#+end_larger

# #+begin_larger
# PDB: Pattern DataBase ヒューリスティクス
# 
# 注: *プランニングでは理論保証付き下界関数のことをヒューリスティック関数と呼ぶ*
# #+end_larger
* Conclusion

+ Input: Unlabelled pairs of images, initial image, goal image
+ Output: Visualized plans to achieve the goal
+ State AutoEncoder(SAE): VAE with Gumbel-Softmax
+ */Contribution/* : *SAE generates /propositions/ from raw data*

  → *compatible to the symbolic KE systems, classical planners*
+ Latplan α : *A simplified prototype*

  → Can leverege from the development of both symbolic/subsymbolic research

** Future Work (input format)

LatPlan is an *architecture* : Any system with SAE is a LatPlan implementation

*Different SAE allows LatPlan to reason about different types of raw data*

+ Autoencoders for *unstructured text* [Li et.al. 2015], *audio* [Deng, Li, et al. 2010]
+ Examples:
  + *This is an apple, this is a pen → oh, ApplePen!* (ugh embarassing)
    
    when actions resembling "word concatenation" was learned
+ */SAE + Automated Planning/* will bring AI to a whole new level
  
  e.g. *1000 steps of optimal reasoning over natural language*

+ 
  #+begin_alignright
  *Hire me! I'm finding a Postdoc position ☺*
  #+end_alignright

#+begin_note
 "A hierarchical neural autoencoder for paragraphs and documents." (2015)

 "Binary coding of speech spectrograms using a deep auto-encoder." (2010)
#+end_note

* Appendix

** I expect mixed responses such as:

#+begin_larger
+ Wait, what!? You /solved/ the symbol grounding!? (*No*)
+ Huh, I hate deep learning hype, NN cannot be trusted.
  
  (*LatPlan can be trusted*)
+ This is not an action model acquisition / not finding symbols.

  (*We don't do AML; we find different symbols*)
#+end_larger
** Did we find symbols? It doesn't sound like what I think symbols are

#+begin_smaller
You /solved/ the symbol grounding!? / This is not finding symbols. / This isn't a action model acquisition.
#+end_smaller

*PDDL implies there are several kinds of symbols and we solved only /one/ issue*

+ Each issue requires a different approach. LatPlan should be combined with these work.

  |                  | <c>                     |
  | Types of symbols | addressed by            |
  |------------------+-------------------------|
  | *Propositions*   | *SAE*                   |
  | Objects          | R-CNN (Computer Vision) |
  | Predicates       | ???                     |
  | Actions          | ???                     |

** Did we find symbols? Why not individual pixels? Why DL?

*Systems based on individual pixels lack generalization*

+ Noise / variations can make the data entirely different

  [[png:results/noise]]

+ must acquire the *generalized features*

+ = a nonlinear function that recognize the entanglements between multiple pixels

** Learning vs Planning
  
 Main differences: Purposes and the abstraction layer

 #+begin_container-fluid
 #+begin_row-fluid
 #+begin_span6
 *Machine Learning, Neural Networks* 
 
 for *Recognition, Reflex*
 + *Subsymbolic Input* (continuous)
   
   Images, Audio, unstructured text: 
 + *Soft Intelligence*:
   
   　 */Reflex Agent/, /Immediate/ actions*
   #+begin_smaller
   *Pavlov's dog* : bell → drool

   *Autonomous Driving* : Pedestrian → Stop.

   *Machine Translation* : Sentence → Sentence

   *Eval. Function for Go* : board → win-rate
   #+end_smaller
   #+begin_larger
   ☺ Efficient 1-to-1 mapping
   
   ☹ Simple tasks
   #+end_larger
 #+end_span6
 #+begin_span6
 *Deliberation, Search*

 for *Planning, Game, Theorem Proving*
 + *Symbolic Input/Output*
   
   Logic, objects, induction rules
 + *Hard Intelligence by Logic:*

   　 */Multi-step/ strategies*
   
   #+begin_smaller
   *Rescue Robot* : actions → help the surviver

   *Theorem Proving* : theorems → QED

   *Compiler* : x86 instructions
   
   *Game of Go* : stones → Win
   #+end_smaller
   #+begin_larger
   ☺ Ordering constraint + complex tasks
   #+end_larger
 #+end_span6
 #+end_row-fluid
 #+end_container-fluid

+ AlphaGo = Subsymbolic (DLNN eval. function) + Symbolic (MCTS)

** Human-Competitive Systems

 AlphaGo = Subsymbolic (NN eval. func) + Symbolic (MCTS)
 + However, *domain-specific* -- specialized in Go, "Grids" / "Stones" are known
 + *Huge expert trace DB* --- Not applicable when data are scarse (e.g. *space exploration*)
 + */Is supervised learning necessary for human?/*
  
   *True intelligence should search / collect data by itself*

 DQN = Subsymbolic (DLNN) + Reinforcement Learning (DLNN)

Domain-independent Atari Game solver (Invader, Packman…), however:
 + RL Acting: Greedily follow the learned policy → *no deliberation!*
 + You can survive most Atari games *by reflex*
  
 # 実際 *Sokoban など論理思考ゲームでは性能が悪い* ↔ 倉庫番ソルバ

** Latplan Advantages

#+begin_xlarge
*/Perception/* based on DLNN
#+end_xlarge

--- Robust systems augmented by the latest DL tech

#+begin_xlarge
*/Decision Making/* based on Classical Planning
#+end_xlarge

--- *Better Theoretical Guarantee than Reinforcement Learning*

#+begin_center
*Completeness* (Finds solution whenever possible), */Solution Optimality/*
#+end_center

--- *Decision Making Independent from Learning*

#+begin_center
*/Unsupervised/* (No data required), *Explainable* (Search by logic)
#+end_center

# 今まではNNとの相性から強化学習が優勢だったが *もうその必要はない*

** When Latplan returns a /wrong/ solution?

*Machine learning may contain errors* (convergence /only on/ $t\rightarrow \infty$, not on real time)

+ Images → Fraud symbols/model/graph

+ *Optimal path on a fraud graph* or *graph disconnected*
  
  A* completeness, soundness, optimality (admissible heuristics) 

+ Fraud visualized plan (noisy) / no plan found

#+begin_center
#+begin_larger
LatPlan may make */wrong observations/* but no */wrong decisions/*
#+end_larger

BTW, "correctness" is defined by error prone observations by humans anyways ...
#+end_center

#+begin_alignright
 (completeness, optimality) → better reliablility than Reinforcement Learning
#+end_alignright

*** Reinforcement Learning

Not only *perception* but *decision making also depends on training*

+ */Each training result does not have admissibility/*

+ */When the learned policy is wrong, the solution could be suboptimal/*

#+begin_quote
... AlphaGo was unprepared for Lee Sedol’s Move 78 because it
didn’t think that a human would ever play it.

#+begin_alignright
Cade Metz. "In Two Moves, that Redifined the Future." /Wired/, 2016
#+end_alignright
#+end_quote

#+begin_center
#+begin_larger
RL may make *wrong decisions*.
#+end_larger
#+end_center

** Future Work (SAE)

SAE can generate propositional symbols (state $s = \{q,r\ldots\}$)

+ 1st-order logic (predicate $p(a,b)$ )

+ We need *object recognition from images* (parameters $a,b$)

+ SAE with networks for object recognition (e.g. R-CNN) should achieve this

** SAE implementation in LatPlan α

Keras, Adam optimizer (learning rate:0.001)

  1764(42x42)

  [→FC(4000,ReLu)→Batchnorm→Dropout(0.4)] × 2

  →FC(49,GumbelSoftmax) (variational loss)

  [→FC(4000,ReLu)→Batchnorm→Dropout(0.4)] × 2

  →1764(42x42) (loss: Binary crossentropy)

　

+ Why full-connected layers ? ::
             Main focus is on *whether propositions made by SAE are feasible*
             
             *→No complication due to CNN, ResNet, etc...* (but I have a working implementation)
             
+ Training on 8-puzzle ::
               *12000 images* out of entire states (362880) → *Generalization*

** Domain Acquisition implementation in LatPlan α (_/NOT our core contribution/_)

_Entire transitions $R$_ → $Encode(R)$ → PDDL

Why? → *Trivial domain acquisition, no generalization*

: Ground      actions 0011 → 0101  (state variables are fully specified)
: Generalized actions *01* → *10*  (state variables are partially specified)

+ LatPlanα: No generalization wrto domain acquisition ::

     Main focus is on */SAE/: whether propositions made by SAE are /feasible/*
             
     *→No complication due to domain acquisition*
     
     *Developping a generalizer is an entirely different topic*, we leave it to existing work

+ We made flour and demonstrated a sugarless cookie with it. ::

     Others study how to make the most beautiful piece of chocolate cake from given flour

     --- which is future work. (flour = symbol)

     Domain acquisition typically requires exisiting models (such as Semi-MDP)

     We made *inputs* for existing work.

#+begin_note
[Konidaris et.al. 14; Cresswell et al 13]
#+end_note

** Why symbols?

Symbols are strong abstraction mechanisms becasue

+ Meanings do not matter ::
     You do not have to understand it: Does a symbol $X$ mean an apple or a car?
 
     Logical reasoning can be performed by mechanical application of rules
     
     + Domain-independent planning : *mystery* vs *nomystery*

       Logistic domains where *symbol names are mangled* (truck → shark)

+ Composable :: 
     A latent vector is a conjunction (and)
     
     Heuristic functions use modus ponens to derive guidance

** More details

GTX1070, PhenomII X6 (3.4GHz OC), 16GB Mem

+ Training: ~30 min
+ Solving: ~3 sec

*** State AutoEncoder (Train data)

1: $x$ 2: $z$ 3: $y$ 4: $round(z)$ 5: $Decode(round(z))$

[[spng:experiment/autoencoding_train]]

*** State AutoEncoder (Validation)

1: $x$ 2: $z$ 3: $y$ 4: $round(z)$ 5: $Decode(round(z))$

[[spng:experiment/autoencoding_test]]

*** State AutoEncoder

Input 2: intial/goal images

[[spng:experiment/init_goal]]

*** PDDL Domain Definition

Examples in $N=25$ (in the paper we bypassed PDDL-SAS converter though)

#+begin_src lisp
(define (domain latent)
 (:requirements :strips :negative-preconditions)
 (:predicates (z0) (z1) (z2) (z3) (z4) (z5) (z6) (z7) (z8) (z9) (z10)
  (z11) (z12) (z13) (z14) (z15) (z16) (z17) (z18) (z19) (z20) (z21)
  (z22) (z23) (z24))
 (:action a10000010010110111100011111000010001011111110011111
  :parameters () :precondition
  (and (z0) (not (z1)) (not (z2)) (not (z3)) (not (z4)) (not (z5))
       (z6) (not (z7)) (not (z8)) (z9) (not (z10)) (z11) (z12)
       (not (z13)) (z14) (z15) (z16) (z17) (not (z18)) (not (z19))
       (not (z20)) (z21) (z22) (z23) (z24))
  :effect (and (z5) (not (z6)) (z13) (z20)))
 (:action a10000010010110111100011110000001001011011110001110
  ...
#+end_src

*** Results in one place

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6

[[png:results/mnist-plan]]

[[png:results/mandrill-plan]]

#+end_span6
#+begin_span6

[[png:results/hanoi3]]

[[png:results/hanoi4]]

[[png:results/lights-out]]

[[png:results/lights-out-skewed]]
#+end_span6
#+end_row-fluid
#+end_container-fluid

*** Fast Downward Log Trace (Search Statistics)                    :noexport:


#+begin_example
reading input... [t=5.479e-05 (sec)]
...
Building successor generator...done! [t=31.7737 (sec)]
done initalizing global data [t=31.7738 (sec)]
Conducting best first search with reopening closed nodes, (real) bound = 2147483647
Initializing landmark cut heuristic...
f = 4 [1 evaluated, 0 expanded, t=36.1569 (sec), 1054016 KB]
...
f = 12 [339 evaluated, 183 expanded, t=843.001 (sec), 1054016 KB]
f = 13 [553 evaluated, 314 expanded, t=1357.62 (sec), 1054016 KB]
f = 14 [942 evaluated, 529 expanded, t=2288.7 (sec), 1054016 KB]
Solution found!
Actual search time: 2688.73 (sec) [t=2724.89 (sec)]
a11010000010010000101001111101100010001000010100111 (1)
...
a10011100111110010010011011001111010111011001001111 (1)
a10011110101110110010011111001011001111011001001111 (1)
Plan length: 14 step(s).
Expanded 631 state(s).
Evaluated 1140 state(s).
Generated 1924 state(s).
Dead ends: 24 state(s).
Search time: 2693.06 (sec)
Total time: 2724.89 (sec)
#+end_example

** Does it have something to do with symbolic planning (BDDs) ?

No.

